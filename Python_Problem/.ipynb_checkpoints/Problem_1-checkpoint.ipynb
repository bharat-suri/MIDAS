{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDAS Summer Internship Task\n",
    "### Problem 1: Python Problem\n",
    "_For this problem, I will be dividing the notebook into two different segments. The first half of the notebook will fetch the tweets using Twitter API and save those tweets in a JSON file. The second half of this notebook is for parsing the previously saved file and displaying the results as mentioned in the problem statement._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the Tweets\n",
    "Here, I am using the requests library to authenticate the account on Twitter API and then using the same account, I will execute a search query. Once I have the search results, I will write them to a JSON file locally and then use it in the second half of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import base64\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.twitter.com/'\n",
    "client_key = '[CLIENT KEY]'\n",
    "client_secret = '[CLIENT SECRET KEY]'\n",
    "file_name = 'data/midas_tweets.json'\n",
    "\n",
    "\n",
    "def generate_key(client_key, client_secret):\n",
    "    key_secret = '{}:{}'.format(client_key, client_secret).encode('ascii')\n",
    "    b64_encoded_key = base64.b64encode(key_secret)\n",
    "    b64_encoded_key = b64_encoded_key.decode('ascii')\n",
    "    \n",
    "    return b64_encoded_key\n",
    "\n",
    "\n",
    "def authenticate(encoded_key):\n",
    "    auth_url = '{}oauth2/token'.format(base_url)\n",
    "    \n",
    "    auth_headers = {\n",
    "        'Authorization': 'Basic {}'.format(encoded_key),\n",
    "        'Content-Type': 'application/x-www-form-urlencoded;charset=UTF-8'\n",
    "    }\n",
    "    \n",
    "    auth_data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    \n",
    "    auth_resp = requests.post(auth_url, headers=auth_headers, data=auth_data)\n",
    "    \n",
    "    if auth_resp.status_code == 200:\n",
    "        return auth_resp.json()['access_token']\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def search(access_token):\n",
    "    \"\"\"This uses the Premium API, for Standard API,\n",
    "    use 1.1/search/tweets.json as search_url and\n",
    "    'q' as the parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add the environment name\n",
    "    search_url = '{}1.1/tweets/search/fullarchive/<ENV>.json'.format(base_url)\n",
    "    \n",
    "    search_headers = {\n",
    "        'Authorization': 'Bearer {}'.format(access_token)\n",
    "    }\n",
    "    \n",
    "    search_params = {\n",
    "        'query': 'from:midasIIITD',\n",
    "        'fromDate': '200603210000'\n",
    "    }\n",
    "    \n",
    "    search_resp = requests.get(search_url, headers=search_headers, params=search_params)\n",
    "    \n",
    "    if search_resp.status_code == 200:\n",
    "        return search_resp.json()\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# Driver Code\n",
    "\n",
    "b64_key = generate_key(client_key, client_secret)\n",
    "access_token = authenticate(b64_key)\n",
    "\n",
    "if access_token:\n",
    "    tweet_data = search(access_token)\n",
    "    if tweet_data:\n",
    "        with open(file_name, 'w+') as json_file:\n",
    "            for tweet in tweet_data['results']:\n",
    "                json.dump(tweet, json_file)\n",
    "                json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Tweets\n",
    "Now as we have the fetched tweets saved into a JSON file, we can start parsing the results by reading the file and then saving the output in a csv format. I will use the pandas library to create a Data Frame and view the tweets in a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_text(tweet):\n",
    "    \"\"\"\n",
    "    I have generalised this method to include the text\n",
    "    even if the tweet is a quoted or a retweeted one.\n",
    "    \"\"\"\n",
    "    if 'quoted_status' in tweet.keys():\n",
    "        rt = 'RT @{} '.format(tweet['quoted_status']['user']['screen_name'])\n",
    "        if tweet['truncated']:\n",
    "            rt = rt + tweet['extended_tweet']['full_text']\n",
    "        else:\n",
    "            rt = rt + tweet['text']\n",
    "        return rt + ' ' + extract_text(tweet['quoted_status'])\n",
    "    elif 'retweeted_status' in tweet.keys():\n",
    "        rt = 'RT @{} '.format(tweet['retweeted_status']['user']['screen_name'])\n",
    "        return rt + extract_text(tweet['retweeted_status'])\n",
    "    else:\n",
    "        if tweet['truncated']:\n",
    "            return tweet['extended_tweet']['full_text']\n",
    "        else:\n",
    "            return tweet['text']\n",
    "\n",
    "\n",
    "def extract_values(tweet):\n",
    "    values = {}\n",
    "    values['Date/Time'] = str(dt.strptime(tweet['created_at'], date_time_format))\n",
    "    values['Likes'] = tweet['favorite_count']\n",
    "    values['Retweets'] = tweet['retweet_count']\n",
    "    values['Text'] = extract_text(tweet)\n",
    "\n",
    "    if tweet['truncated']:\n",
    "        if 'media' in tweet['extended_tweet']['entities'].keys():\n",
    "            entities = tweet['extended_tweet']['entities']\n",
    "            images = len([x for x in entities['media'] if x['type'] == 'photo'])\n",
    "            if images == 0:\n",
    "                values['Images'] = None\n",
    "            else:\n",
    "                values['Images'] = images\n",
    "    else:\n",
    "        if 'media' in tweet['entities'].keys():\n",
    "            entities = tweet['entities']\n",
    "            images = len([x for x in entities['media'] if x['type'] == 'photo'])\n",
    "            if images == 0:\n",
    "                values['Images'] = None\n",
    "            else:\n",
    "                values['Images'] = images\n",
    "    return values\n",
    "\n",
    "# Driver Code\n",
    "\n",
    "df = pd.DataFrame(columns=['Text', 'Date/Time', 'Likes', 'Retweets', 'Images'])\n",
    "date_time_format = \"%a %b %d %H:%M:%S +0000 %Y\"\n",
    "with open(file_name, 'r+') as json_file:\n",
    "    for line in json_file:\n",
    "        json_line = json.loads(line)\n",
    "        df = df.append(extract_values(json_line), ignore_index=True)\n",
    "        df = df.where(df.notnull(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@IEEEBigMM19 is also available on Facebook now...</td>\n",
       "      <td>2019-03-20 08:19:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @IEEEBigMM19 BigMM 2019 : IEEE BigMM 2019 –...</td>\n",
       "      <td>2019-03-20 02:40:07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BigMM 2019 : IEEE BigMM 2019 – Call for Worksh...</td>\n",
       "      <td>2019-03-18 02:27:47</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Congratulations @midasIIITD team, Rohan, Prady...</td>\n",
       "      <td>2019-03-17 14:22:04</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have emailed the task details to all shortl...</td>\n",
       "      <td>2019-03-16 14:06:56</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IEEE BigMM 2019 - Call for Workshop Proposals....</td>\n",
       "      <td>2019-03-16 09:20:29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Congratulations! Arijit, Ramit, @debanjanbhucs...</td>\n",
       "      <td>2019-03-16 09:14:58</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We will be releasing a very interesting task t...</td>\n",
       "      <td>2019-03-16 05:13:14</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @hcdiiitd Last day to register for #Portfol...</td>\n",
       "      <td>2019-03-13 17:09:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@ACMMM19 @sigmm @TheOfficialACM @acmmmsys @ACM...</td>\n",
       "      <td>2019-03-13 04:11:24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @ACMMM19 The paper deadline is approaching....</td>\n",
       "      <td>2019-03-13 04:06:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @kaggle Bookmark this amazing library of im...</td>\n",
       "      <td>2019-03-12 17:43:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Awesome members of our @midasIIITD team who ar...</td>\n",
       "      <td>2019-03-12 14:37:55</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@saanidhi @ACMMM19 Before Friday, 15th March.</td>\n",
       "      <td>2019-03-11 14:58:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We are glad to inform that Adobe is launching ...</td>\n",
       "      <td>2019-03-11 12:02:42</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We will email tasks to all shortlisted candida...</td>\n",
       "      <td>2019-03-11 11:54:38</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@ACMMM19 @ACM_MM2018 @acmmm17 @sigmm @ACM Less...</td>\n",
       "      <td>2019-03-11 06:22:12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @kdnuggets Face Recognition using One-Shot ...</td>\n",
       "      <td>2019-03-11 06:17:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@AvinashSwamina2 @IIITDelhi No. They will be g...</td>\n",
       "      <td>2019-03-08 13:22:07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>We are in the process of finalizing the shortl...</td>\n",
       "      <td>2019-03-08 13:15:34</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@ylecun @NilayShri @the_dhumketu @debanjanbhuc...</td>\n",
       "      <td>2019-03-06 13:44:11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @kdnuggets Python Data Science for Beginner...</td>\n",
       "      <td>2019-03-06 11:12:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @stanfordnlp Useful feature of our Python s...</td>\n",
       "      <td>2019-03-03 19:36:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@NilayShri @NilayShri, Certain thing! The next...</td>\n",
       "      <td>2019-03-03 17:09:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>At @midasIIITD, we not only work hard but also...</td>\n",
       "      <td>2019-03-03 15:37:28</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Considering several requests to extend the dea...</td>\n",
       "      <td>2019-03-03 14:55:31</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT @jeremyphoward 39 studies about human perce...</td>\n",
       "      <td>2019-03-03 14:26:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Correction:   @midasIIITD at @IIITDelhi</td>\n",
       "      <td>2019-03-02 17:43:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Thanks much to all aspirants who have applied ...</td>\n",
       "      <td>2019-03-02 09:59:03</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @kdnuggets Keras Hyperparameter Tuning in G...</td>\n",
       "      <td>2019-02-28 14:21:21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>@RealAAAI 2019 summary for @midasIIITD.\\n1 pap...</td>\n",
       "      <td>2019-02-02 05:05:16</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>@the_dhumketu @RealAAAI Congrats! Raghav, Kshi...</td>\n",
       "      <td>2019-02-01 07:46:57</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Our paper titled, \"Mind Your Language: Abuse a...</td>\n",
       "      <td>2019-02-01 07:30:53</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RT @PeterMartigny Very interesting talk by @Ch...</td>\n",
       "      <td>2019-02-01 03:15:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RT @NilayShri @midasIIITD @RatnRajiv\\n@the_dhu...</td>\n",
       "      <td>2019-02-01 03:13:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CFP for @ACMMM19 has been posted on WikiCFP. K...</td>\n",
       "      <td>2019-01-31 06:57:04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>@midasIIITD Lab is pleased to share our novel ...</td>\n",
       "      <td>2019-01-31 05:50:19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RT @RatnRajiv If you are attending @RealAAAI a...</td>\n",
       "      <td>2019-01-31 05:32:43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RT @RatnRajiv Great to be part of this year's ...</td>\n",
       "      <td>2019-01-30 19:46:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RT @MIT Want to squelch fake news? Let the rea...</td>\n",
       "      <td>2019-01-30 17:18:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>If you are attending @RealAAAI 2019 at Honolul...</td>\n",
       "      <td>2019-01-30 05:00:29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>If you are attending @RealAAAI 2019 then visit...</td>\n",
       "      <td>2019-01-29 19:42:10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>If you are attending @RealAAAI 2019 then visit...</td>\n",
       "      <td>2019-01-29 19:39:29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>If you are attending @RealAAAI 2019 then visit...</td>\n",
       "      <td>2019-01-29 19:31:35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>@TechAtBloomberg @debanjanbhucs It is a great ...</td>\n",
       "      <td>2019-01-29 18:05:01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>RT @TechAtBloomberg Learn more about the colla...</td>\n",
       "      <td>2019-01-29 18:03:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RT @debanjanbhucs We as researchers working at...</td>\n",
       "      <td>2019-01-29 17:52:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RT @kdnuggets 7 Steps to Mastering Basic Machi...</td>\n",
       "      <td>2019-01-29 14:52:24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>@TechAtBloomberg @debanjanbhucs @IIITDelhi @Ra...</td>\n",
       "      <td>2019-01-29 05:17:27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RT @TechAtBloomberg #Textanalytics researcher ...</td>\n",
       "      <td>2019-01-29 04:40:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>RT @kdnuggets Top 16 #OpenSource #DeepLearning...</td>\n",
       "      <td>2019-01-28 12:11:29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RT @Princeton Using data from more than 6,000 ...</td>\n",
       "      <td>2019-01-28 12:11:13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>RT @CornellBirds In 1929 Cornell Lab founder A...</td>\n",
       "      <td>2019-01-28 12:10:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>RT @seb_ruder Natural Questions: A new QA data...</td>\n",
       "      <td>2019-01-25 08:56:54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RT @kdnuggets 10 More #Free Must-Read #Books f...</td>\n",
       "      <td>2019-01-24 15:43:25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @kdnuggets How to build an API for a machin...</td>\n",
       "      <td>2019-01-24 15:42:59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@ACMMM19 @ACM @abhinavdhall consider submittin...</td>\n",
       "      <td>2019-01-23 10:24:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RT @ACMMM19 Jump start your @ACM #Multimedia w...</td>\n",
       "      <td>2019-01-23 10:23:34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@NUSComputing Congratulations! Yaman @the_dhum...</td>\n",
       "      <td>2019-01-22 14:04:40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>⚡️ “Achievements”\\n\\nhttps://t.co/LvZt1GTY4C</td>\n",
       "      <td>2019-01-22 14:02:51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text            Date/Time  \\\n",
       "0   @IEEEBigMM19 is also available on Facebook now...  2019-03-20 08:19:24   \n",
       "1   RT @IEEEBigMM19 BigMM 2019 : IEEE BigMM 2019 –...  2019-03-20 02:40:07   \n",
       "2   BigMM 2019 : IEEE BigMM 2019 – Call for Worksh...  2019-03-18 02:27:47   \n",
       "3   Congratulations @midasIIITD team, Rohan, Prady...  2019-03-17 14:22:04   \n",
       "4   We have emailed the task details to all shortl...  2019-03-16 14:06:56   \n",
       "5   IEEE BigMM 2019 - Call for Workshop Proposals....  2019-03-16 09:20:29   \n",
       "6   Congratulations! Arijit, Ramit, @debanjanbhucs...  2019-03-16 09:14:58   \n",
       "7   We will be releasing a very interesting task t...  2019-03-16 05:13:14   \n",
       "8   RT @hcdiiitd Last day to register for #Portfol...  2019-03-13 17:09:44   \n",
       "9   @ACMMM19 @sigmm @TheOfficialACM @acmmmsys @ACM...  2019-03-13 04:11:24   \n",
       "10  RT @ACMMM19 The paper deadline is approaching....  2019-03-13 04:06:04   \n",
       "11  RT @kaggle Bookmark this amazing library of im...  2019-03-12 17:43:44   \n",
       "12  Awesome members of our @midasIIITD team who ar...  2019-03-12 14:37:55   \n",
       "13      @saanidhi @ACMMM19 Before Friday, 15th March.  2019-03-11 14:58:30   \n",
       "14  We are glad to inform that Adobe is launching ...  2019-03-11 12:02:42   \n",
       "15  We will email tasks to all shortlisted candida...  2019-03-11 11:54:38   \n",
       "16  @ACMMM19 @ACM_MM2018 @acmmm17 @sigmm @ACM Less...  2019-03-11 06:22:12   \n",
       "17  RT @kdnuggets Face Recognition using One-Shot ...  2019-03-11 06:17:20   \n",
       "18  @AvinashSwamina2 @IIITDelhi No. They will be g...  2019-03-08 13:22:07   \n",
       "19  We are in the process of finalizing the shortl...  2019-03-08 13:15:34   \n",
       "20  @ylecun @NilayShri @the_dhumketu @debanjanbhuc...  2019-03-06 13:44:11   \n",
       "21  RT @kdnuggets Python Data Science for Beginner...  2019-03-06 11:12:30   \n",
       "22  RT @stanfordnlp Useful feature of our Python s...  2019-03-03 19:36:04   \n",
       "23  @NilayShri @NilayShri, Certain thing! The next...  2019-03-03 17:09:48   \n",
       "24  At @midasIIITD, we not only work hard but also...  2019-03-03 15:37:28   \n",
       "25  Considering several requests to extend the dea...  2019-03-03 14:55:31   \n",
       "26  RT @jeremyphoward 39 studies about human perce...  2019-03-03 14:26:40   \n",
       "27            Correction:   @midasIIITD at @IIITDelhi  2019-03-02 17:43:05   \n",
       "28  Thanks much to all aspirants who have applied ...  2019-03-02 09:59:03   \n",
       "29  RT @kdnuggets Keras Hyperparameter Tuning in G...  2019-02-28 14:21:21   \n",
       "..                                                ...                  ...   \n",
       "70  @RealAAAI 2019 summary for @midasIIITD.\\n1 pap...  2019-02-02 05:05:16   \n",
       "71  @the_dhumketu @RealAAAI Congrats! Raghav, Kshi...  2019-02-01 07:46:57   \n",
       "72  Our paper titled, \"Mind Your Language: Abuse a...  2019-02-01 07:30:53   \n",
       "73  RT @PeterMartigny Very interesting talk by @Ch...  2019-02-01 03:15:27   \n",
       "74  RT @NilayShri @midasIIITD @RatnRajiv\\n@the_dhu...  2019-02-01 03:13:23   \n",
       "75  CFP for @ACMMM19 has been posted on WikiCFP. K...  2019-01-31 06:57:04   \n",
       "76  @midasIIITD Lab is pleased to share our novel ...  2019-01-31 05:50:19   \n",
       "77  RT @RatnRajiv If you are attending @RealAAAI a...  2019-01-31 05:32:43   \n",
       "78  RT @RatnRajiv Great to be part of this year's ...  2019-01-30 19:46:11   \n",
       "79  RT @MIT Want to squelch fake news? Let the rea...  2019-01-30 17:18:40   \n",
       "80  If you are attending @RealAAAI 2019 at Honolul...  2019-01-30 05:00:29   \n",
       "81  If you are attending @RealAAAI 2019 then visit...  2019-01-29 19:42:10   \n",
       "82  If you are attending @RealAAAI 2019 then visit...  2019-01-29 19:39:29   \n",
       "83  If you are attending @RealAAAI 2019 then visit...  2019-01-29 19:31:35   \n",
       "84  @TechAtBloomberg @debanjanbhucs It is a great ...  2019-01-29 18:05:01   \n",
       "85  RT @TechAtBloomberg Learn more about the colla...  2019-01-29 18:03:31   \n",
       "86  RT @debanjanbhucs We as researchers working at...  2019-01-29 17:52:23   \n",
       "87  RT @kdnuggets 7 Steps to Mastering Basic Machi...  2019-01-29 14:52:24   \n",
       "88  @TechAtBloomberg @debanjanbhucs @IIITDelhi @Ra...  2019-01-29 05:17:27   \n",
       "89  RT @TechAtBloomberg #Textanalytics researcher ...  2019-01-29 04:40:47   \n",
       "90  RT @kdnuggets Top 16 #OpenSource #DeepLearning...  2019-01-28 12:11:29   \n",
       "91  RT @Princeton Using data from more than 6,000 ...  2019-01-28 12:11:13   \n",
       "92  RT @CornellBirds In 1929 Cornell Lab founder A...  2019-01-28 12:10:37   \n",
       "93  RT @seb_ruder Natural Questions: A new QA data...  2019-01-25 08:56:54   \n",
       "94  RT @kdnuggets 10 More #Free Must-Read #Books f...  2019-01-24 15:43:25   \n",
       "95  RT @kdnuggets How to build an API for a machin...  2019-01-24 15:42:59   \n",
       "96  @ACMMM19 @ACM @abhinavdhall consider submittin...  2019-01-23 10:24:14   \n",
       "97  RT @ACMMM19 Jump start your @ACM #Multimedia w...  2019-01-23 10:23:34   \n",
       "98  @NUSComputing Congratulations! Yaman @the_dhum...  2019-01-22 14:04:40   \n",
       "99       ⚡️ “Achievements”\\n\\nhttps://t.co/LvZt1GTY4C  2019-01-22 14:02:51   \n",
       "\n",
       "   Likes Retweets Images  \n",
       "0      1        1   None  \n",
       "1      0        0   None  \n",
       "2      6        3   None  \n",
       "3     15        4   None  \n",
       "4      6        0   None  \n",
       "5      1        1   None  \n",
       "6      7        2   None  \n",
       "7      7        2   None  \n",
       "8      0        0   None  \n",
       "9      1        0      1  \n",
       "10     0        0   None  \n",
       "11     0        0   None  \n",
       "12    16        4      1  \n",
       "13     0        0   None  \n",
       "14     4        0   None  \n",
       "15     3        0   None  \n",
       "16     1        1   None  \n",
       "17     0        0   None  \n",
       "18     1        0   None  \n",
       "19     8        4   None  \n",
       "20     3        0   None  \n",
       "21     0        0      1  \n",
       "22     0        0   None  \n",
       "23     1        0   None  \n",
       "24     9        1      3  \n",
       "25     6        2   None  \n",
       "26     0        0   None  \n",
       "27     1        0   None  \n",
       "28     7        1   None  \n",
       "29     0        0      1  \n",
       "..   ...      ...    ...  \n",
       "70     7        3      4  \n",
       "71     3        1   None  \n",
       "72    24        3      1  \n",
       "73     0        0   None  \n",
       "74     0        0   None  \n",
       "75     1        1   None  \n",
       "76     4        2   None  \n",
       "77     0        0   None  \n",
       "78     0        0   None  \n",
       "79     0        0      1  \n",
       "80     3        1      1  \n",
       "81     5        2   None  \n",
       "82     3        1   None  \n",
       "83     2        1   None  \n",
       "84     5        2   None  \n",
       "85     0        0   None  \n",
       "86     0        0   None  \n",
       "87     0        0      1  \n",
       "88     3        1      1  \n",
       "89     0        0   None  \n",
       "90     0        0   None  \n",
       "91     0        0   None  \n",
       "92     0        0   None  \n",
       "93     0        0   None  \n",
       "94     0        0   None  \n",
       "95     0        0      1  \n",
       "96     0        0   None  \n",
       "97     0        0   None  \n",
       "98     1        1   None  \n",
       "99     3        1   None  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/tweets_formatted.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
